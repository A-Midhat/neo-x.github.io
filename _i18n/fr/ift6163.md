# Cours sur l'apprentissage des robots (agents du monde réel)

<div align="center">
    <table align="center">
        <tr>
            <td width="33%">
                <img width="100%" src="/assets/projects/SMiRL/vizdoom/vizdoom_dtl.gif">
            </td>
            <td width="33%">
                <img width="100%" src="/assets/projects/DiscoRL/DisCoRL.png">
            </td>
            <td width="33%">
                <img width="100%" src="/assets/projects/ReLMM/complex_room_short.gif">
            </td>
        </tr>

        <tr>
            <td width="33%">Apprentissage à partir d'images</td>
            <td width="33%">Apprentissage des fonctions de récompense</td>
            <td width="33%">Apprentissage dans le monde réel</td>
        </tr>
    </table>
</div>

J'enseigne un cours sur l'apprentissage automatique pour le monde réel. Ce cours se concentre sur les méthodes d'apprentissage par renforcement profond et leur application au contrôle de systèmes du monde réel (robotique, etc). [Voici un lien](https://diro.umontreal.ca/public/FAS/diro/Documents/1-Programmes-cours/Horaires/2023Hiver2Cyc.html) pour trouver le cours offert sur la page web du DIRO en tant que IFT 6163.

Des méthodes d'apprentissage telles que l'apprentissage par renforcement profond ont montré leur succès dans la résolution de problèmes de planification et de contrôle simulés, mais elles peinent à produire des comportements diversifiés et intelligents sur des systèmes interagissant dans le monde réel (robots). Cette classe vise à discuter de ces limitations, à étudier des méthodes pour les surmonter et à permettre aux agents de s'entraîner de manière autonome, de devenir des systèmes d'apprentissage et d'adaptation nécessitant peu de supervision. À la fin du cours, chaque étudiant devrait avoir une solide compréhension des différentes techniques pour entraîner des agents à accomplir des tâches dans le monde réel. Les techniques abordées dans le cours incluent, entre autres, l'apprentissage par renforcement, l'apprentissage par renforcement par lots, l'apprentissage multi-tâches, l'apprentissage basé sur un modèle, Sim2Real, l'apprentissage hiérarchique, l'apprentissage basé sur des objectifs, l'apprentissage multi-agent, la fragilité de l'apprentissage par renforcement, la prise de décisions au niveau méta et l'apprentissage des fonctions de récompense.

## Objectifs du cours

Apprendre les concepts fondamentaux de l'apprentissage automatique pour les applications robotiques. Ces concepts sont considérés comme avancés et nécessitent une bonne base en apprentissage automatique, apprentissage profond et apprentissage par renforcement. Cela implique :

- Se familiariser avec les principaux types de modèles d'apprentissage automatique pour une politique de contrôle (du basé sur un modèle au sans modèle).
- Développer la capacité de lire des articles de recherche, de les contextualiser et de développer un esprit critique.
- Développer des compétences en présentation.
- Développer son autonomie dans la recherche en apprentissage automatique.
- Développer des compétences liées aux forces et aux faiblesses des méthodes actuelles d'apprentissage automatique lorsqu'elles sont appliquées à des problèmes du monde réel.

## Prérequis du cours

Vous devez avoir terminé ou suivre en parallèle l'un des cours suivants (ou leur équivalent).

- [IFT 6390, Fondements de l'apprentissage automatique](https://mitliagkas.github.io/ift6390-ml-class/)
- [IFT 6758B](http://admission.umontreal.ca/cours-et-horaires/cours/IFT-6758B/) Data science
- [IFT6269 : Modèles graphiques probabilistes et apprentissage](http://www-labs.iro.umontreal.ca/~slacoste/teaching/ift6269/A21/)

Le cours utilisera également fortement Python. Je partirai du principe que vous avez des connaissances en algèbre linéaire, en probabilité, en statistiques, en planification, en optimisation et en systèmes d'exploitation (par exemple, le multithreading et la gestion de la mémoire). Vous devrez également être capable de lire et de comprendre des articles de recherche de NeurIPS, RSS, ICRA, CoRL et ICLR.

## Cours couvrant des sujets liés aux robots d'apprentissage ainsi que des devoirs de programmation et un projet final

Les objectifs des devoirs et des projets finaux seront les suivants :

- Connaissance logicielle : Apprendre à connaître les logiciels disponibles pour l'apprentissage par renforcement profond.
- Compétences d'analyse : Recueillir des statistiques appropriées des résultats et utiliser des ordinateurs serveurs et des conteneurs Docker pour reproduire des expériences et valider les résultats.
- Proposition d'une nouvelle idée à explorer pour le projet final basée sur les cours.
- Apprendre à comprendre le potentiel d'une méthode dans le monde réel (positif ou négatif, social et environnemental).
- Exploration avec le projet final : Investigation plus libre de sujets avancés du cours produisant un code réutilisable, des résultats reproductibles et un rapport écrit.
- Estimation de l'impact que la nouvelle idée pourrait avoir dans un contexte industriel.

Le projet final sera réalisé en équipe de deux. La recherche en milieu académique et industriel implique de travailler avec d'autres pour atteindre les objectifs de recherche. Ce projet évaluera les idées des étudiants, leur compréhension du processus de recherche, leur travail d'équipe et leurs compétences en présentation.

En ce qui concerne les cours, l'instructeur proposera des cours en direct sur les sujets chaque semaine, en mettant l'accent sur leur compréhension, leur application et leurs limites.

## APPROCHE ÉVALUATIVE ET POIDS (indicatif uniquement)
- 40 % : Devoirs de programmation. (Cela est nécessaire pour acquérir les compétences nécessaires pour réaliser un bon projet final dans le cours)
- 10 % : Participation en classe et discussion des lectures.
- 15 % : Examen partiel sur les concepts.
- 35 % : Projet final

### Devoirs de programmation

Les devoirs de programmation couvrent des sujets importants pour effectuer des recherches combinant l'apprentissage automatique et les robots. Ils couvriront :

- Clonage de comportement et apprentissage par imitation
- Méthodes d'apprentissage sans modèle (PPO) et basées sur un modèle (DDPG ou PETS)
- Méthodes d'exploration et de préformation, telles que l'apprentissage hiérarchique et l'apprentissage basé sur des objectifs
- Exploration sécurisée
- Apprentissage des fonctions de récompense (RL supervisé/non supervisé)

Les devoirs sont également conçus pour familiariser les étudiants avec les logiciels nécessaires pour effectuer des recherches :

- Bibliothèques d'apprentissage profond, telles que PyTorch ou TensorFlow
- Contraintes matérielles lors de la manipulation de vrais robots (puissance, calcul, limites mécaniques)
- Calcul distribué pour effectuer des expériences appropriées
- Visualisation et analyse (la partie la plus importante)

### Projet final

Le projet final est conçu pour permettre aux étudiants d'appliquer les compétences apprises dans un domaine qui les intéresse tout en approfondissant les concepts. Votre projet n'a pas besoin d'utiliser du matériel de robotique réel, mais il existe des options pour obtenir du matériel pour ce cours. Chaque projet commencera par une proposition qui garantira la bonne portée de chaque projet. Les projets se feront en groupes de 2 ou 3 étudiants. Cependant, pour donner quelques idées sur la portée, voici quelques exemples.

- Réimplémenter une méthode dans un nouveau cadre d'apprentissage profond
- Réimplémenter une méthode dans un article qui n'a pas publié de code (honte à eux)
- Choisir un robot, l'acquérir et former un modèle pour accomplir une tâche, comme marcher.
- Enquêter sur une nouvelle méthode qui améliore l'exploration
- Enquêter sur une nouvelle méthode pour apprendre une meilleure représentation pour l'apprentissage et l'exploration.
- Étudier Sim2Real en apprenant et en transférant des politiques vers une autre simulation ou un matériel de robotique réel.
- Effectuer une revue de la littérature des articles Sim2Real.

L'un des objectifs généraux du projet de classe est également d'affiner vos compétences pour définir des projets raisonnables qui peuvent être menés à bien et qui sont de qualité suffisante.

### Matériel de robotique réelle

Pour utiliser du matériel réel dans votre projet de classe, vous devez inclure le matériel demandé dans la proposition de projet. Le cours dispose de fonds alloués pour l'achat de matériel pour les projets.

Quelques idées de robots pour les projets

- [Hexapod](https://www.trossenrobotics.com/phantomx-ax-hexapod.aspx)
- [iRobot](https://edu.irobot.com/what-we-offer/create-robot)
- [PiCrwaler](https://www.sunfounder.com/products/picrawler-robot-kit)
- [Locobot](http://www.locobot.org/)
- [Bras ReactorX150](http://support.interbotix.com/html/specifications/rx150.html)

## Ressources

Certains contenus liés au cours seront utiles à examiner.

### Autres cours connexes

- <a href="http://rail.eecs.berkeley.edu/deeprlcourse/">Apprentissage par renforcement profond avec Sergey Levine</a>
- <a href="https://www.coursera.org/learn/machine-learning">Apprentissage automatique avec Andrew Ng</a>
- <a href="https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/">Apprentissage automatique avec Nando de Freitas</a>
- <a href="https://cs231n.github.io/">Réseaux neuronaux avec Andrej Karpathy</a>
- <a href="https://www.davidsilver.uk/teaching/">Apprentissage par renforcement avec David Silver</a>
- <a href="https://cs330.stanford.edu/">Apprentissage multi-tâches et méta-apprentissage profonds avec Chelsea Finn</a>

### Manuels pertinents

- <a href="http://www.deeplearningbook.org/">Ian Goodfellow, Yoshua Bengio et Aaron Courville, Deep Learning</a>
- <a href="http://incompleteideas.net/book/the-book-2nd.html">Sutton & Barto, Apprentissage par renforcement : Une introduction (2e édition)</a>
- <a href="http://www.ualberta.ca/~szepesva/RLBook.html">Szepesvari, Algorithmes pour l'apprentissage par renforcement</a>
- <a href="http://www.athenasc.com/dpbook.html">Bertsekas, Programmation dynamique et contrôle optimal, Vols I et II</a>
- <a href="http://www.wiley.com/WileyCDA/WileyTitle/productCd-0471727822.html">Puterman, Processus décisionnels markoviens : Programmation dynamique stochastique discrète</a>
- <a href="http://adp.princeton.edu/">Powell, Programmation dynamique approximative</a>
