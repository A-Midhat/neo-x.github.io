---
layout: page
title: Publications
permalink: /publications/
---

## Preprints
* **Maximum Reward Formulation In Reinforcement Learning.**  
Sai Krishna Gottipati, Yashaswi Pathak, Rohan Nuttall, Raviteja Chunduru, Ahmed Touati, Sriram Ganapathi Subramanian, Matthew E Taylor, Sarath Chandar.  
In arXiv, 2020.  
\[[arXiv](https://arxiv.org/abs/2010.03744)\]

* **MLMLM: Link Prediction with Mean Likelihood Masked Language Model.**  
Louis Clouatre, Philippe Trempe, Amal Zouaq, Sarath Chandar.  
In arXiv, 2020.  
\[[arXiv](https://arxiv.org/abs/2009.07058)\]

* **How To Evaluate Your Dialogue System: Probe Tasks as an Alternative for Token-level Evaluation Metrics.**  
Prasanna Parthasarathi, Joelle Pineau, Sarath Chandar.  
In arXiv, 2020.  
\[[arXiv](https://arxiv.org/abs/2008.10427)\], \[[code](https://github.com/ppartha03/Dialogue-Probe-Tasks-Public)\]

* **PatchUp: A Regularization Technique for Convolutional Neural Networks.**  
Mojtaba Faramarzi, Mohammad Amini, Akilesh Badrinaaraayanan, Vikas Verma, Sarath Chandar.  
In arXiv, 2020.  
\[[arXiv](https://arxiv.org/abs/2006.07794)\], \[[code](https://github.com/chandar-lab/PatchUp)\]  


## Conference and Journal Papers
# 2020
0. **The LoCA Regret: A Consistent Metric to Evaluate Model-Based Behavior in Reinforcement Learning.**  
Harm van Seijen, Hadi Nekoei, Evan Racah, Sarath Chandar.  
Neural Information Processing Systems (NeurIPS), 2020.  
\[[arXiv](https://arxiv.org/abs/2007.03158)\], \[[code](https://github.com/chandar-lab/LoCA)\]

0. **Learning To Navigate The Synthetically Accessible Chemical Space Using Reinforcement Learning.**  
Sai Krishna Gottipati*, Boris Sattarov*, Sufeng Niu, Yashaswi Pathak, Haoran Wei, Shengchao Liu, Karam MJ Thomas,
Simon Blackburn, Connor W Coley, Jian Tang, Sarath Chandar, Yoshua Bengio.  
International Conference on Machine Learning (ICML), 2020.  
\[[arXiv](https://arxiv.org/abs/2004.12485)\]
{: reversed="reversed"}

