
@article{li2024reinforcement,
      title={Reinforcement Learning for Versatile, Dynamic, and Robust Bipedal Locomotion Control}, 
      author={Zhongyu Li and Xue Bin Peng and Pieter Abbeel and Sergey Levine and Glen Berseth and Koushil Sreenath},
      year={Preprint},
      arxiv={2401.16889},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      journal   = {Under submission},
      video={youtu.be/sQEnDbET75g},
}

@inproceedings{CreusSOFE2023,
  title={	
Improving Intrinsic Exploration by Creating Stationary Objectives},
  author={Roger Creus Castanyer and Joshua Romoff and Glen Berseth},
      arxiv={2310.18144},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=YbZxT0SON4}
}

@inproceedings{Ghugarem2023,
  title={	
Closing the Gap between {TD} Learning and Supervised Learning - A Generalisation Point of View},
  author={Raj Ghugare and Matthieu Geist and Benjamin Eysenbach and Glen Berseth},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=qg5JENs0N4},
 arxiv={2401.11237},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{DEMOIS,
  author    = {Charlie Gauthier and Florian Golemo and Glen Berseth and Liam Paull},
  title     = {Fearful Goal Generation for Robust Policy Learning},
  journal   = {CoRL 2022 workshop on Learning for Agile Robotics},
  url={https://openreview.net/forum?id=3cxan6Ygrv},
  year={PrePrint}
}

@article{DemeuleInariant,
  title={	
Adaptive Resolution Residual Networks},
  author={L{\'e}a Demeule and Mahtab Sandhu, and Glen Berseth},
 publisher = {Curran Associates, Inc.},
  journal = {The Symbiosis of Deep Learning and Differential Equations III - a NeurIPS2023 workshop (Oral)},
  year={PrePrint},
  url={https://openreview.net/forum?id=9hcsB4oYxG}
}

@inproceedings{PatilTABA,
  title={	
Intelligent Switching for Reset-Free {RL}},
  author={Darshan Patil and Janarthanan Rajendran and Glen Berseth and Sarath Chandar},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=Nq45xeghcL}
}

@article{MadanGFNGCRL,
  title={	
Hierarchical Reinforcement Learning with partially specified goals using Generative Flow Networks},
  author={Kanika Madan and Albert Zhan and Alex Lamb and Emmanuel Bengio and Glen Berseth and Yoshua Bengio},
 publisher = {Curran Associates, Inc.},
  journal = {(In submission)},
  year={PrePrint}
}

@article{HuggensonSurpriseAdapt,
  title={	
Surprise-Adaptive Intrinsic Motivation for Unsupervised Reinforcement Learning},
  author={Adriana Knatchbull-Hugessen and Roger Creus-Castanyer and Glen Berseth},
  year={Preprint},
  primaryClass={cs.LG},
  journal   = {Intrinsically-Motivated and Open-Ended Learning Workshop at NeurIPS2023},
  url={https://openreview.net/forum?id=E0LWTN1xPX}
}

@inproceedings{GhugaremChemRL,
  title={	
Searching the space of high-value molecules using reinforcement learning and language models},
  author={Raj Ghugare and Santiago Miret and Adriana Hugessen and Mariano Phielipp and Glen Berseth},
  arxiv={2310.02902},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=nqlymMx42E}
}

@inproceedings{VenkatramanDiffuSkill,
      title={Reasoning with Latent Diffusion in Offline Reinforcement Learning}, 
      author={Siddarth Venkatraman and Shivesh Khaitan and Ravi Tej Akella and John Dolan and Jeff Schneider and Glen Berseth},
      arxiv={2309.06599},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=tGQirjzddO}
}

@inproceedings{jain2023maximum,
    title={Maximum State Entropy Exploration using Predecessor and Successor Representations},
    author={Arnav Kumar Jain and Lucas Lehnert and Irina Rish and Glen Berseth},
    year={2023},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    arxiv={2306.14808},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
    url={https://openreview.net/forum?id=tFsxtqGmkn}
}

@inproceedings{gao2023bootstrapping,
      title={Bootstrapping Adaptive Human-Machine Interfaces with Offline Reinforcement Learning}, 
      author={Jensen Gao and Siddharth Reddy and Glen Berseth and Anca D. Dragan and Sergey Levine},
      year={2023},
      arxiv={2309.03839},
  booktitle = {Proc. IEEE/RSJ Intl Conf on Intelligent Robots and Systems (IROS 2023)},
  arxiv = {2208.01160},
  projectpage = "https://sites.google.com/view/orbit-assist",
  abstract = {daptive interfaces can help users perform sequential decision-making tasks like robotic teleoperation given noisy, high-dimensional command signals (e.g., from a brain-computer interface). Recent advances in human-in-the-loop machine learning enable such systems to improve by interacting with users, but tend to be limited by the amount of data that they can collect from individual users in practice. In this paper, we propose a reinforcement learning algorithm to address this by training an interface to map raw command signals to actions using a combination of offline pre-training and online fine-tuning. To address the challenges posed by noisy command signals and sparse rewards, we develop a novel method for representing and inferring the user's long-term intent for a given trajectory. We primarily evaluate our method's ability to assist users who can only communicate through noisy, high-dimensional input channels through a user study in which 12 participants performed a simulated navigation task by using their eye gaze to modulate a 128-dimensional command signal from their webcam. The results show that our method enables successful goal navigation more often than a baseline directional interface, by learning to denoise user commands signals and provide shared autonomy assistance. We further evaluate on a simulated Sawyer pushing task with eye gaze control, and the Lunar Lander game with simulated user commands, and find that our method improves over baseline interfaces in these domains as well. Extensive ablation experiments with simulated user commands empirically motivate each component of our method.},
}


@article{kim2023torque,
  author={Kim, Donghyeon and Glen Berseth and Schwartz, Mathew and Park, Jaeheung},
  journal={IEEE Robotics and Automation Letters}, 
  title={Torque-based Deep Reinforcement Learning for Task-and-Robot Agnostic Learning on Bipedal Robots Using Sim-to-Real Transfer}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={In this paper, we review the question of which action space is best suited for controlling a real biped robot in combination with Sim2Real training. Position control has been popular as it has been shown to be more sample efficient and intuitive to combine with other planning algorithms. However, for position control, gain tuning is required to achieve the best possible policy performance. We show that, instead, using a torque-based action space enables task-and-robot agnostic learning with less parameter tuning and mitigates the sim-to-reality gap by taking advantage of torque control's inherent compliance. Also, we accelerate the torque-based-policy training process by pre-training the policy to remain upright by compensating for gravity. The paper showcases the first successful sim-to-real transfer of a torque-based deep reinforcement learning policy on a real human-sized biped robot.},
  keywords={},
  arxiv={2304.09434},
  video={https://www.youtube.com/watch?v=CR6pTS39VRE},
  doi={10.1109/LRA.2023.3304561},
  ISSN={2377-3766},
  month={},}

@inproceedings{
	li2023robust,
	author={Zhongyu Li and Xue Bin Peng and Pieter Abbeel and Sergey Levine and Glen Berseth and Koushil Sreenath},
	editor={Kostas E. Bekris and Kris Hauser and Sylvia L. Herbert and Jingjin Yu},
	title={Robust and Versatile Bipedal Jumping Control through Reinforcement Learning},
	booktitle={Robotics: Science and Systems XIX, Daegu, Republic of Korea, July 10-14, 2023},
	year={2023},
	url={https://doi.org/10.15607/RSS.2023.XIX.052},
	doi={10.15607/RSS.2023.XIX.052},
    arxiv={2302.09450},
    video={https://youtu.be/aAPSZ2QFB-E},
    image={papers/cassiejump.png}
}

@inproceedings{quadsoccer,
  author    = {Yandong Ji and Zhongyu Li* and Yinan Sun and Xue Bin Peng and Sergey Levine and Glen Berseth and Koushil Sreenath},
  title     = {Hierarchical Reinforcement Learning for Precise Soccer Shooting Skills using a Quadrupedal Robot },
  booktitle = {Proc. IEEE/RSJ Intl Conf on Intelligent Robots and Systems (IROS 2022)},
  arxiv = {2208.01160},
  image = {papers/a-reinforcement-learni-1.jpg},
  video = {https://www.youtube.com/watch?v=bteipHcJ8BM},
  abstract = {We address the problem of enabling quadrupedal robots to perform precise shooting skills in the real world using reinforcement learning. Developing algorithms to enable a legged robot to shoot a soccer ball to a given target is a challenging problem that combines robot motion control and planning into one task. To solve this problem, we need to consider the dynamics limitation and motion stability during the control of a dynamic legged robot. Moreover, we need to consider motion planning to shoot the hard-to-model deformable ball rolling on the ground with uncertain friction to a desired location. In this paper, we propose a hierarchical framework that leverages deep reinforcement learning to train (a) a robust motion control policy that can track arbitrary motions and (b) a planning policy to decide the desired kicking motion to shoot a soccer ball to a target. We deploy the proposed framework on an A1 quadrupedal robot and enable it to accurately shoot the ball to random targets in the real world. },
  year={2022}
}

@article{Traboco2022,
  title={AnyMorph: Learning Transferable Policies By Inferring Agent Morphology},
  author={Brandon Trabucco and Phielipp Mariano and Glen Berseth},
  journal   = {Internation Conference on Machine Learning},
  arxiv = {2206.12279},
  image = {papers/anymorph_prompt.gif},
  projectpage = {https://mila.quebec/en/article/anymorph-learning-transferable-policies-by-inferring-agent-morphology/},
  abstract = {The prototypical approach to reinforcement learning involves training policies tailored to a particular agent from scratch for every new morphology. Recent work aims to eliminate the re-training of policies by investigating whether a morphology-agnostic policy, trained on a diverse set of agents with similar task objectives, can be transferred to new agents with unseen morphologies without re-training. This is a challenging problem that required previous approaches to use hand-designed descriptions of the new agent's morphology. Instead of hand-designing this description, we propose a data-driven method that learns a representation of morphology directly from the reinforcement learning objective. Ours is the first reinforcement learning algorithm that can train a policy to generalize to new agent morphologies without requiring a description of the agent's morphology in advance. We evaluate our approach on the standard benchmark for agent-agnostic control, and improve over the current state of the art in zero-shot generalization to new agents. Importantly, our method attains good performance without an explicit description of morphology. },
  year={2022}
}

@article{fickinger2021explore,
  title={Explore and Control with Adversarial Surprise},
  author={Fickinger, Arnaud and Jaques, Natasha and Parajuli, Samyak and Chang, Michael and Rhinehart, Nicholas and Glen Berseth and Russell, Stuart and Levine, Sergey},
  arxiv = {2107.07394},
  image = {papers/eac.png},
  projectpage = {https://sites.google.com/view/adversarial-surprise/home},
  video = {https://youtu.be/ipSd1_txOr8},
  journal   = {CoRR},
  volume    = {abs/2107.07394},
  year      = {2021},
  url       = {https://arxiv.org/abs/2107.07394},
  eprinttype = {arXiv},
  eprint    = {2107.07394},
  timestamp = {Wed, 21 Jul 2021 15:55:35 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2107-07394.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{rhinehart2021intrinsic,
  title={Intrinsic Control of Variational Beliefs in Dynamic Partially-Observed Visual Environments},
  author={Rhinehart, Nicholas and Wang, Jenny and Glen Berseth and Co-Reyes, John D and Hafner, Danijar and Finn, Chelsea and Levine, Sergey},
 publisher = {Curran Associates, Inc.},

  booktitle = {Advances in Neural Information Processing Systems},
 volume = {34},
 year = {2021}
}
}
}


@article{x2text,
  title={X2T: Training an X-to-Text Typing Interface with Online Learning from Implicit Feedback},
  author={Jensen Gao and Sid Reddy and Glen Berseth and Anca Dragon and Sergey Levine},
  journal={International Conference on Learning Representations (ICLR) 2021},
  year      = {2020},

}

@inproceedings{
co-reyes2021accelerating,
title={Accelerating Online Reinforcement Learning via Model-Based Meta-Learning},
author={John D Co-Reyes and Sarah Feng and Glen Berseth and Jie Qui and Sergey Levine},
booktitle={Learning to Learn - Workshop at ICLR 2021},
year={2021},
url={https://openreview.net/forum?id=XCJ5PEkuMkC},
}

@article{disco,
  title={DisCo RL: Distribution-Conditioned Reinforcement Learning for General-Purpose Policies},
  author={Soroush Nasiriany and   Vitchyr H. Pong and  Ashvin Nair and  Alexander Khazatsky and Glen Berseth and  Sergey Levine},
  journal={International Conference on Robotics and Automation (ICRA 2021)},
  year      = {2021},
  url = {https://ieeexplore.ieee.org/document/9561402},
  arxiv={2104.11707},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  projectpage={https://sites.google.com/view/disco-rl},
}

@inproceedings{realmm,
  title={Fully Autonomous Real-World Reinforcement Learning with Applications to Mobile Manipulation},
  author={Charles Sun and Coline Devin and Brian Yang and Jędrzej Orbik and Abhishek Gupta and Glen Berseth and Sergey Levine},
 booktitle = {Conference on Robot Learning (CoRL)},
	series = {CoRL '21},
	year = {2021},
	keywords = {Robotics, Deep Reinforcement Learning, Autonomous Learning},
	video= {https://youtu.be/PcYJoCe4Kr4},
}

@article{asha,
  title={ASHA: Assistive Teleoperation via Human-in-the-Loop Reinforcement Learning},
  author={Sean Chen* and Jensen Gao* and Siddharth Reddy and Glen Berseth and Anca D. Dragan and Sergey Levine},
  journal={IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2022},
  url={https://dl.acm.org/doi/abs/10.1109/ICRA46639.2022.9812442},
  arxiv = {2202.02465v1},
  image = {papers/asha.png},
  projectpage = {https://sites.google.com/view/asha-assist},
  video = {https://drive.google.com/file/d/1PlnR1o-wa-0XGWwK_4j7TR7YeED8xhKV/view?usp=sharing},
  code = {https://github.com/rddy/asha},
  
}

@article{robustCassie,
  title={Reinforcement Learning for Robust Parameterized Locomotion Control of Bipedal Robots},
  author={Zhongyu Li and Xuxin Cheng and Xue Bin Peng and Pieter Abbeel and Sergey Levine and Glen Berseth and Koushil Sreenath},
  journal={International Conference on Robotics and Automation (ICRA 2021)},
  year      = {2020},

}

@inproceedings{
berseth2022comps,
title={Co{MPS}: Continual Meta Policy Search},
author={Glen Berseth and Zhiwei Zhang and Grace Zhang and Chelsea Finn and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=PVJ6j87gOHz},
arxiv = {2208.01160},
  
  projectpage = {https://mila.quebec/en/article/anymorph-learning-transferable-policies-by-inferring-agent-morphology/},
  video = {https://youtu.be/IAH_qFIQxxc},
}

@article{coreyes2020ecological,
  author    = {John D. Co{-}Reyes and               Suvansh Sanjeev and               Glen Berseth and               Abhishek Gupta and               Sergey Levine},
  title     = {Ecological Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/2006.12478},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.12478},
  eprinttype = {arXiv},
  eprint    = {2006.12478},
  timestamp = {Tue, 23 Jun 2020 17:57:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-12478.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},

}

@ARTICLE{berseth2019smirl,
    title={SMiRL: Surprise Minimizing Reinforcement Learning in Unstable Environments},
    author={Glen Berseth and Daniel Geng and Coline Manon Devin and Nicholas Rhinehart and Chelsea Finn and Dinesh Jayaraman and Sergey Levine},
    booktitle={International Conference on Learning Representations \textbf{(Oral, top 1.8\% of submissions)}},
    year={2021},
    url={https://openreview.net/forum?id=cPZOyoDloxl},
    video={https://youtu.be/ps0dsFXQszQ},
    projectpage={https://sites.google.com/view/surpriseminimization},
    arxiv={1912.05510},
}

@article{8964083,
  title={Gamification of Crowd-Driven Environment Design},
  author={Haworth, Michael Brandon and Usman, Muhammad and Schaumann, Davide and Chakraborty, Nilay and Berseth Glen and Faloutsos, Petros and Kapadia, Mubbasir},
  journal={IEEE Computer Graphics and Applications},
  year={2020},
  publisher={IEEE},

}

@article{MAVRC,
  title={Morphology-Agnostic Visual Robotic Control},
  author={Yang, Brian and Jayaraman, Dinesh and Berseth Glen and Efros, Alexei and Levine, Sergey},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={2},
  pages={766--773},
  year={2020},
  publisher={IEEE},

}

@inproceedings{CC-RIG,
	author = {Ashvin Nair$^*$ and Shikhar Bahl$^*$ and Alexander Khazatsky$^*$ and Vitchyr Pong and Glen Berseth and Sergey Levine},
	title = {Contextual Imagined Goals for Self-Supervised Robotic Learning},
	booktitle = {Conference on Robot Learning (CoRL)},
	series = {CoRL '19},
	year = {2019},
	location = {Osaka, Japan},
	keywords = {Robotics, Deep Reinforcement Learning, Self-Supervision},
	arxiv = {2208.01160},
  
  projectpage = {https://mila.quebec/en/article/anymorph-learning-transferable-policies-by-inferring-agent-morphology/},
  video = {https://www.youtube.com/watch?v=bteipHcJ8BM},
} 

@article{8013477,
  title={Evaluating and optimizing evacuation plans for crowd egress},
  author={Cassol, Vincius J and Testa, Est{\^e}v{\~a}o Smania and Jung, Cl{\'a}udio Rosito and Usman, Muhammad and Faloutsos, Petros and Berseth Glen and Kapadia, Mubbasir and Badler, Norman I and Musse, Soraia Raupp},
  journal={IEEE computer graphics and applications},
  volume={37},
  number={4},
  pages={60--71},
  year={2017},
  publisher={IEEE},

}


@ARTICLE{Berseth2023-tn,
  title     = "Towards Learning to Imitate from a Single Video Demonstration",
  author    = "Berseth, Glen and Golemo, Florian and Pal, Christopher",
  abstract  = "Agents that can learn to imitate behaviours observed in
               video--without having direct access to internal state or action
               information of the observed agent--are more suitable for
               learning in …",
  journal   = "J. Mach. Learn. Res.",
  publisher = "jmlr.org",
  volume    =  24,
  number    =  78,
  pages     = "1--26",
  year      =  2023,
  url       = {https://www.jmlr.org/papers/v24/21-1174.html},
  image = {papers/virl.png},
  video={https://youtu.be/B93_B7tBTc0},
  projectpage={https://neo-x.github.io/blog/2019/05/25/VizImitation.html},
  html={https://sites.google.com/view/virl1},
}

@article{CHER,
  author    = {Abdul Rahman Kreidieh and Glen Berseth and Brandon Traboco Samyak Parajuli and               Sergey Levine and               Alexandre M. Bayen},
  title     = {Inter-Level Cooperation in Hierarchical Reinforcement Learning},
  journal   = {Under submission to Journal of Machine Learning Research},
  arxiv={1912.02368},
  year={Preprint}
}

@article{terrainRLSim,
  author    = {Glen Berseth and
               Xue Bin Peng and
               Michiel van de Panne},
  title     = {Terrain {RL} Simulator},
  journal   = {CoRR},
  volume    = {abs/1804.06424},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.06424},
  archivePrefix = {arXiv},
  eprint    = {1804.06424},
  timestamp = {Mon, 13 Aug 2018 16:46:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1804-06424},
  bibsource = {dblp computer science bibliography, https://dblp.org},

}

@inproceedings{cassie,
  author    = {Zhaoming Xie and
               Glen Berseth and
               Patrick Clary and
               Jonathan W. Hurst and
               Michiel van de Panne},
  title     = {Feedback Control For Cassie With Deep Reinforcement Learning},
  booktitle = {Proc. IEEE/RSJ Intl Conf on Intelligent Robots and Systems (IROS 2018)},
  year={2018},

}

@inproceedings{MBAE,
  title={Model-Based Action Exploration for Learning Dynamic Motion Skills},
  author={Glen Berseth and Alex Kyriazis and Ivan Zinin and William Choi and Michiel van de Panne},
  booktitle = {Proc. IEEE/RSJ Intl Conf on Intelligent Robots and Systems (IROS 2018)},
  year={2018},
  video={https://youtu.be/yjomPyWZRhY},
}

@inproceedings{deepcrowds,
 author = {Berseth Glen * and Haworth*, Brandon and Kapadia, Mubbasir and Faloutsos, Petros},
 title = {Deep Integration of Physical Humanoid Control and Crowd Navigation (\textbf{best paper runner up})},
 booktitle = {Proceedings of the 13th International Conference on Motion in Games},
 series = {MIG '20},
 year = {2020},
 publisher = {ACM},
 address = {New York, NY, USA},

} 

@inproceedings{Usman:2017:PES:3136457.3136458,
 author = {Usman, Muhammad and Haworth, Brandon and Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
 title = {Perceptual Evaluation of Space in Virtual Environments},
 booktitle = {Proceedings of the Tenth International Conference on Motion in Games},
 series = {MIG '17},
 year = {2017},
 isbn = {978-1-4503-5541-4},
 location = {Barcelona, Spain},
 pages = {16:1--16:10},
 articleno = {16},
 numpages = {10},
 acmid = {3136458},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {architecture, navigation, perceptual study, spatial analysis, virtual reality},

} 

@inproceedings{Chakraborty:2017:CSC:3136457.3136463,
 author = {Chakraborty, Nilay and Haworth, Brandon and Usman, Muhammad and Berseth Glen and Faloutsos, Petros and Kapadia, Mubbasir},
 title = {Crowd Sourced Co-design of Floor Plans Using Simulation Guided Games},
 booktitle = {Proceedings of the Tenth International Conference on Motion in Games},
 series = {MIG '17},
 year = {2017},
 isbn = {978-1-4503-5541-4},
 location = {Barcelona, Spain},
 pages = {1:1--1:5},
 articleno = {1},
 numpages = {5},
 acmid = {3136463},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {architectural design, co-design, gamification},

} 

@article{density_flow_relationship,
  title={On density flow relationships during crowd evacuation},
  author={Haworth, Brandon and Usman, Muhammad and Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
  journal={Computer Animation and Virtual Worlds 28 (3-4)},
  year = {2017},

}


@article{PLAiD,
  title={Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control},
  author={Glen Berseth and Cheng Xie and Paul Cernek and Michiel Van de Panne},
  journal={International Conference on Learning Representations (ICLR) 2018},
  year      = {2018},
  video={https://youtu.be/_DjHbHCXGk0},
}

@article{peng2017hikeRL,
  title={DeepLoco: Dynamic Locomotion Skills Using Hierarchical Deep Reinforcement Learning},
  author={Peng, Xue Bin and Berseth Glen and Yin, KangKang and van de Panne, Michiel},
  journal={SIGGRAPH 2017},
  year      = {2017},

}

@article{uDOME,
  author    = {Glen Berseth and Brandon Haworth and Muhammad Usman and Davide Schaumann and Mahyar Khayatkhoei and  Mubbasir Kapadia and Petros Faloutsos},
  title     = {Interactive Architectural Design with Diverse Solution Exploration},
  journal   = {IEEE Transactions on Visualization and Computer Graphics},
  year      = {2019},
  dio       = {10.1109/TVCG.2019.2938961},
  video={https://youtu.be/xtbln0XfBWA},
}

@inproceedings{usmanGI2017,
  title={Understanding spatial perception and visual modes in the review of architectural designs},
  author={Usman, Muhammad and Haworth, Brandon and Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
  booktitle={Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation, 31},
  year = {2017},

}

@article{berseth2016acclmesh,
  title={ACCLMesh: curvature-based navigation mesh generation},
  author={Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
  journal={Computer Animation and Virtual Worlds},
  volume={27},
  number={3-4},
  pages={195--204},
  year={2016},

}

@article{CODE2017,
  title={CODE: Crowd Optimized Design of Environments},
  author={Haworth, Brandon and Usman, Muhammad and Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
  journal={Computer Animation and Virtual Worlds},
  year={2017},

}


@article{peng2016terrain,
  title={Terrain-adaptive locomotion skills using deep reinforcement learning},
  author={Peng, Xue Bin and Berseth Glen and van de Panne, Michiel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={35},
  number={4},
  pages={81},
  year={2016},
  publisher={ACM},

}

@inproceedings{haworth2016using,
  title={Using synthetic crowds to inform building pillar placements},
  author={Haworth, Brandon and Usman, Muhammad and Berseth Glen and Khayatkhoei, Mahyar and Kapadia, Mubbasir and Faloutsos, Petros},
  booktitle={Virtual Humans and Crowds for Immersive Environments (VHCIE), IEEE},
  pages={7--11},
  year={2016},
  organization={IEEE},

}

@article{Peng:2015:DTT:2809654.2766910,
 author = {Peng, Xue Bin and Berseth Glen and van de Panne, Michiel},
 title = {Dynamic Terrain Traversal Skills Using Reinforcement Learning},
 journal = {ACM Trans. Graph.},
 issue_date = {August 2015},
 volume = {34},
 number = {4},
 month = jul,
 year = {2015},
 pages = {80:1--80:11},
 articleno = {80},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/2766910},
 doi = {10.1145/2766910},
 acmid = {2766910},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {computer animation, physics simulation},

} 

@article {CAV:CAV1652,
author = {Berseth Glen and Usman, Muhammad and Haworth, Brandon and Kapadia, Mubbasir and Faloutsos, Petros},
title = {Environment optimization for crowd evacuation},
journal = {Computer Animation and Virtual Worlds},
volume = {26},
number = {3-4},
issn = {1546-427X},
url = {http://dx.doi.org/10.1002/cav.1652},
doi = {10.1002/cav.1652},
pages = {377--386},
keywords = {crowd simulation, optimization and analysis},
year = {2015},
abstract = {The layout of a building, real or virtual, affects the flow patterns of its intended users. It is well established, for example, that the placement of pillars at proper locations can often facilitate pedestrian flow during the evacuation of a building. Such considerations are therefore important for architects, game level developers, and others whose domains involve agents navigating through buildings. In this paper, we take the first steps towards developing a simulation framework that can be used to study the optimal placement of architectural elements, such as pillars or doors, for the purposes of facilitating dense pedestrian flow during the evacuation of a building. In particular, we show that the steering algorithms used to model the local navigation abilities of the agents significantly affect the results, which motivates the need for a statistically valid approach and further study. Copyright © 2015 John Wiley & Sons, Ltd.},
  video = {https://youtu.be/EEO35f1WV2k},
}

@inproceedings{Berseth:2014:COG:2668064.2668100,
 author = {Berseth Glen and Haworth, M. Brandon and Kapadia, Mubbasir and Faloutsos, Petros},
 title = {Characterizing and Optimizing Game Level Difficulty},
 booktitle = {Proceedings of the Seventh International Conference on Motion in Games},
 series = {MIG '14},
 year = {2014},
 isbn = {978-1-4503-2623-0},
 location = {Playa Vista, California},
 pages = {153--160},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2668084.2668100},
 doi = {10.1145/2668084.2668100},
 acmid = {2668100},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {game elements, optimization, procedural content generation, static analysis},

} 

@article {CASA2015:RobustFootsteps,
author = {Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
title = {Robust Space-Time Footsteps for Agent-Based Steering (best short paper)},
journal = {Computer Animation and Virtual Worlds},
isbn = {978-981-09-4946-4},
keywords = {Crowd Simulation, Footsteps, Planning and Analysis},
year = {2015},
abstract = {Recent agent-based steering methods abandon the standard particle abstraction of an agent's locomotion abilities and employ more complex models from timed footsteps to physics-based controllers. These models often provide the action space of an optimal search method that plans a sequence of steering actions for each agent that minimize a performance criterion. The transition from particle-based models to more complex models is not straightforward and gives rise to a number of technical challenges. For example, a disk geometry is constant, symmetric and convex, while a footstep model maybe non-convex and dynamic. In this paper, we identify general challenges associated with footstep-based steering approaches and present a new space-time footstep planning steering model that is robust to challenging scenario configurations.},
  video = {https://youtu.be/m7gfoeIzTSQ},
}

@inproceedings{SCA14:113-122:2014,
author = {Glen Berseth and Mubbasir Kapadia and Brandon Haworth and Petros Faloutsos },
title = {SteerFit: Automated Parameter Fitting for Steering Algorithms},
pages = {113-122},
url = {http://diglib.eg.org/EG/DL/WS/SCA/SCA14/113-122.pdf},
doi = {10.2312/sca.20141129},
abstract = {In the context of crowd simulation, there is a diverse set of algorithms that model steering. The performance of steering approaches, both in terms of quality of results and computational efficiency, depends on internal parameters that are manually tuned to satisfy application-specific requirements. This paper investigates the effect that these parameters have on an algorithm's performance. Using three representative steering algorithms and a set of established performance criteria, we perform a number of large scale optimization experiments that optimize an algorithm's parameters for a range of objectives. For example, our method automatically finds optimal parameters to minimize turbulence at bottlenecks, reduce building evacuation times, produce emergent patterns, and increase the computational efficiency of an algorithm. We also propose using the Pareto Optimal front as an efficient way of modelling optimal relationships between multiple objectives, and demonstrate its effectiveness by estimating optimal parameters for interactively defined combinations of the associated objectives. The proposed methodologies are general and can be applied to any steering algorithm using any set of performance criteria.},
	year= {2014},
	isbn = {978-3-905674-61-3},
	issn = {1727-5288},
	location = {Copenhagen, Denmark},
	publisher = {Eurographics Association},
	journal = {Eurographics/ ACM SIGGRAPH Symposium on Computer Animation},
	booktitle = {Eurographics/ ACM SIGGRAPH Symposium on Computer Animation},
}

@inproceedings{Berseth:2015:ACN:2822013.2822043,
 author = {Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
 title = {ACCLMesh: Curvature-based Navigation Mesh Generation},
 booktitle = {Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games},
 series = {MIG '15},
 year = {2015},
 isbn = {978-1-4503-3991-9},
 location = {Paris, France},
 pages = {97--102},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2822013.2822043},
 doi = {10.1145/2822013.2822043},
 acmid = {2822043},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {crowd simulation, curvature, navigation mesh},

} 

@inproceedings{Haworth:2015:EOL:2822013.2822040,
 author = {Haworth, Brandon and Usman, Muhammad and Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
 title = {Evaluating and Optimizing Level of Service for Crowd Evacuations},
 booktitle = {Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games},
 series = {MIG '15},
 year = {2015},
 isbn = {978-1-4503-3991-9},
 location = {Paris, France},
 pages = {91--96},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2822013.2822040},
 doi = {10.1145/2822013.2822040},
 acmid = {2822040},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {crowd evacuation, crowd simulation, environment optimization, level of service, steering algorithms},

} 

@inproceedings{Berseth:2013:SES:2522628.2522650,
author = {Berseth Glen and Kapadia, Mubbasir and Faloutsos, Petros},
title = {SteerPlex: Estimating Scenario Complexity for Simulated Crowds},
booktitle = {Proceedings of Motion on Games},
series = {MIG '13},
year = {2013},
isbn = {978-1-4503-2546-2},
location = {Dublin 2, Ireland},
pages = {45:67--45:76},
articleno = {45},
numpages = {10},
url = {http://doi.acm.org/10.1145/2522628.2522650},
doi = {10.1145/2522628.2522650},
acmid = {2522650},
publisher = {ACM},
address = {New York, NY, USA},
keywords = {crowd analysis, crowd simulation, scenario complexity},
} 

@inproceedings{codeLBW,
 author = {Haworth, Brandon and Usman, Muhammad and Berseth Glen and Khayatkhoei, Mahyar and Kapadia, Mubbasir and Faloutsos, Petros},
 title = {Towards Computer Assisted Crowd Aware Architectural Design},
 booktitle = {CHI '16 Extended Abstracts},
 series = {CHI EA '16},
 year = {2016},
 isbn = {978-1-4503-2474-8},
 location = {San Jose, CA, USA},
 pages = {2287--2292},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2559206.2581174},
 doi = {10.1145/2559206.2581174},
 acmid = {2581174},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Architectural Optimization, User-in-the-loop design, Crowd
 Simulation},

} 

